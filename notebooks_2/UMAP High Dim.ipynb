{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import umap\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import do_not_circ as dnc\n",
    "import copy\n",
    "%matplotlib inline\n",
    "\n",
    "from src.nets import Nets\n",
    "from src.utils import *\n",
    "from src.postprocessing.postprocessing import *\n",
    "from src.postprocessing.stats_plotting import *\n",
    "from src.postprocessing.interpolation import *\n",
    "\n",
    "from src.save_load import *\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CENTER = \"gold\"\n",
    "COLOR1 = \"thistle\" \n",
    "COLOR2 = \"lightsalmon\" \n",
    "COLOR3 = \"skyblue\" \n",
    "COLOR4 = \"rosybrown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_folder = os.environ[\"PATH_TO_DNC_FOLDER\"]\n",
    "exp = \"\"\n",
    "experiment_folder = os.path.join(root_folder, \"experiments\", exp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_folder = os.path.join(\".\", \"images\", exp)\n",
    "if not os.path.exists(image_folder):\n",
    "    os.mkdir(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = load_configs(experiment_folder)\n",
    "cfgs.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "\n",
    "device = None\n",
    "cfg = cfgs.loc[exp_id]\n",
    "cfg[\"data_meta\"][\"N\"] = 500\n",
    "\n",
    "data_set = get_data(cfg, device=device)\n",
    "data_loader = DataLoader(data_set, batch_size=cfgs.loc[exp_id][\"batch_size\"], shuffle=False)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Center center model \n",
    "center_step = 1001\n",
    "center_idx = 0\n",
    "\n",
    "center_model = get_all_models(experiment_folder, center_step)[exp_id][str(center_idx)]\n",
    "\n",
    "cache_dict[\"center_config\"] = {\n",
    "    \"step\": center_step,\n",
    "    \"idx\": center_idx\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually get models\n",
    "model_steps = [1001, 1001, 1001, 1001]\n",
    "model_idxs = [1, 2, 3, 4]\n",
    "\n",
    "basis_vectors = [get_params_vec(get_all_models(experiment_folder, model_steps[i])[exp_id][str(model_idxs[i])]) \n",
    "                 for i in range(len(model_steps))]\n",
    "\n",
    "cache_dict[\"basis_vectors\"] = \"trained\"\n",
    "cache_dict[\"basis_vectors_config\"] = {\n",
    "    \"steps\": model_steps,\n",
    "    \"model_idxs\": model_idxs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get random models\n",
    "num_parameters = get_model_num_params(center_model)\n",
    "num_dir = 4\n",
    "basis_vectors = torch.randn(num_dir, num_parameters)\n",
    "\n",
    "cache_dict[\"basis_vectors\"] = \"random\"\n",
    "cache_dict[\"basis_vectors_config\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_orthonorm_vectors = create_offset_orthonorm_basis_new(center_model, basis_vectors)\n",
    "basis_orthonorm_vectors = [torch.Tensor(v) for v in basis_orthonorm_vectors]\n",
    "\n",
    "cache_dict[\"basis_orthonorm_vectors\"] = basis_orthonorm_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = get_coordinates(basis_vectors[0], basis_orthonorm_vectors, get_params_vec(center_model))\n",
    "c2 = get_coordinates(basis_vectors[1], basis_orthonorm_vectors, get_params_vec(center_model))\n",
    "c3 = get_coordinates(basis_vectors[2], basis_orthonorm_vectors, get_params_vec(center_model))\n",
    "\n",
    "cO = [0, 0, 0]\n",
    "\n",
    "l1 = get_net_loss(vec_to_net(basis_vectors[0], center_model), data_loader, criterion, full_dataset=True)\n",
    "l2 = get_net_loss(vec_to_net(basis_vectors[1], center_model), data_loader, criterion, full_dataset=True)\n",
    "l3 = get_net_loss(vec_to_net(basis_vectors[2], center_model), data_loader, criterion, full_dataset=True)\n",
    "l4 = get_net_loss(vec_to_net(basis_vectors[3], center_model), data_loader, criterion, full_dataset=True)\n",
    "\n",
    "lO = get_net_loss(center_model, data_loader, criterion, full_dataset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the grid of vectors and the loss values for each grid point\n",
    "num_inter_models = 20\n",
    "grid_bound = [-13, 13]\n",
    "cache_dict[\"num_inter_models\"] = num_inter_models\n",
    "cache_dict[\"grid_bound\"] = grid_bound\n",
    "\n",
    "func = lambda m: get_net_loss(m, data_loader, criterion, full_dataset=True, device=None)\n",
    "\n",
    "\n",
    "\n",
    "grid = get_models_grid(center_model, basis_orthonorm_vectors, num_inter_models, grid_bound)\n",
    "vals = get_model_interpolate_grid(center_model, basis_orthonorm_vectors, num_inter_models, grid_bound, func)\n",
    "\n",
    "\n",
    "cache_data(experiment_folder, \"UMAP_HighD\", vals, meta_dict=cache_dict, time_stamp=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load cache \n",
    "vals, meta_data = load_cached_data(experiment_folder, \"UMAP_HighD\", time_stamp=\"\")\n",
    "\n",
    "grid_bound = meta_data[\"grid_bound\"]\n",
    "num_inter_models = meta_data[\"num_inter_models\"]\n",
    "basis_orthonorm_vectors = meta_data[\"basis_orthonorm_vectors\"]\n",
    "\n",
    "grid_arr = np.linspace(grid_bound[0], grid_bound[1], num_inter_models)\n",
    "\n",
    "grid = get_models_grid(center_model, basis_orthonorm_vectors, num_inter_models, grid_bound)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the grid by loss\n",
    "\n",
    "grid_filter = vals.reshape(-1) <  1e-5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how much remains\n",
    "grid.reshape(np.prod(grid.shape[:-1]), -1)[grid_filter].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit umap \n",
    "# TODO to get where the original vectors lie, append them at the end, or add them or something with their respective losses\n",
    "# and mark them with an x\n",
    "fit = umap.UMAP(n_neighbors=200, min_dist=0.4, metric='euclidean', verbose=True)\n",
    "\n",
    "# add the basis vectors \n",
    "filtered_grid = grid.reshape(np.prod(grid.shape[:-1]), -1)[grid_filter]\n",
    "filtered_grid = np.concatenate([filtered_grid, [get_params_vec(center_model).detach().numpy()], [b.detach().numpy() for b in basis_vectors]])\n",
    "\n",
    "u = fit.fit_transform(filtered_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge fit with labels\n",
    "labels = np.concatenate([vals.reshape(-1)[grid_filter], [lO, l1, l2, l3, l4]])\n",
    "\n",
    "dataset = pd.DataFrame({'x1': u[:-5, 0], 'x2': u[:-5, 1], 'label': labels[:-5]})\n",
    "\n",
    "# Plot\n",
    "sns.set(font_scale=1.4, rc={'figure.figsize':(13, 10)})\n",
    "sns.set_style(\"white\", {'axes.spines.left': False,\n",
    "                         'axes.spines.bottom': False,\n",
    "                         'axes.spines.right': False,\n",
    "                         'axes.spines.top': False})\n",
    "ax = sns.scatterplot(x=\"x1\", y=\"x2\", hue=\"label\",\n",
    "                     data=dataset,\n",
    "                     s=10,\n",
    "                     palette='inferno', \n",
    "                     edgecolor=\"none\")\n",
    "\n",
    "ax = sns.scatterplot(x=u[-5:, 0], y=u[-5:, 1],\n",
    "                     s=300, hue=[COLOR_CENTER, COLOR1, COLOR2, COLOR3, COLOR4], palette=[COLOR_CENTER, COLOR1, COLOR2, COLOR3, COLOR4])\n",
    "\n",
    "ax.set(yticks=[], xticks=[], xlabel='', ylabel='')\n",
    "ax.get_legend().remove()\n",
    "\n",
    "norm = plt.Normalize(0, 1e-5)\n",
    "# norm = plt.Normalize(dataset['label'].min(), dataset['label'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"inferno\", norm=norm)\n",
    "# divider = make_axes_locatable(ax)\n",
    "# cax = divider.append_axes(\"right\", size=\"2%\", pad=0.5)\n",
    "cax = inset_axes(ax,\n",
    "                   width=\"4%\",  # width = 5% of parent_bbox width\n",
    "                   height=\"75%\",  # height : 50%\n",
    "                   loc='center left',\n",
    "                   bbox_to_anchor=(1, 0., 1, 1),\n",
    "                   bbox_transform=ax.transAxes,\n",
    "                   borderpad=0,\n",
    "                   )\n",
    "cbar = ax.figure.colorbar(sm, cax=cax, )\n",
    "cbar.outline.set_visible(False)\n",
    "cbar.ax.tick_params(size=0)\n",
    "cbar.ax.get_yaxis().labelpad = 5\n",
    "cbar.ax.tick_params(labelsize=20)\n",
    "cbar.ax.set_ylabel('J(' + '\\u03B8' + ')', rotation=0, size=20)\n",
    "\n",
    "ax.get_figure().savefig(os.path.join(image_folder, \"UMAP_4d.pdf\"), bbox_inches = 'tight', pad_inches = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['label'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (dnd)",
   "language": "python",
   "name": "dnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
